{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "b_3sHSkE7ei3"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UQYeMFH7if3"
      },
      "source": [
        "# IMPORT SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ZY6uqc6PCw",
        "outputId": "57259442-bbe6-4f54-f896-e67ecc07eae1"
      },
      "source": [
        "!pip install --upgrade music21==6.7.1\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout\n",
        "%load_ext tensorboard \n",
        "from tensorboard import notebook\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting music21==6.7.1\n",
            "  Downloading music21-6.7.1.tar.gz (19.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.2 MB 208 kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from music21==6.7.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from music21==6.7.1) (1.1.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from music21==6.7.1) (8.10.0)\n",
            "Collecting webcolors\n",
            "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: music21\n",
            "  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for music21: filename=music21-6.7.1-py3-none-any.whl size=21941721 sha256=e03b39466a8dbc077c1590277a889f0fef483d6ad74dfca448f3babb60ad20e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/44/61/90e4e65262ca1b4d9f707527b540729ce3f64e00fc6b38d54c\n",
            "Successfully built music21\n",
            "Installing collected packages: webcolors, music21\n",
            "  Attempting uninstall: music21\n",
            "    Found existing installation: music21 5.5.0\n",
            "    Uninstalling music21-5.5.0:\n",
            "      Successfully uninstalled music21-5.5.0\n",
            "Successfully installed music21-6.7.1 webcolors-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE-M7nPx7cm9",
        "outputId": "a4632eb2-fa08-4e29-9181-26b88245dfb9"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "MIDI_PATH=\"/content/drive/My Drive/MLFolder/Onlab/MIDI_Iron_Maiden/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRrSLZ2W7ddN",
        "outputId": "0a6a384a-3eab-455b-8f55-451e166fe61b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 11 15:17:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_3sHSkE7ei3"
      },
      "source": [
        "# UTILITY FUNCTIONS SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E38xCZCS7lGE"
      },
      "source": [
        "def most_frequent(paramlist): \n",
        "    #https://www.geeksforgeeks.org/python-find-most-frequent-element-in-a-list/\n",
        "    counter = 0\n",
        "    num = paramlist[0] \n",
        "      \n",
        "    for i in paramlist: \n",
        "        curr_frequency = paramlist.count(i) \n",
        "        if(curr_frequency> counter): \n",
        "            counter = curr_frequency \n",
        "            num = i \n",
        "  \n",
        "    return num \n",
        "\n",
        "def get_notes_from_chord(chord):\n",
        "    if chord.startswith(\"<music21.chord.Chord \"):\n",
        "        chord = chord[len(\"<music21.chord.Chord \"):]\n",
        "    if chord.endswith(\">\"):\n",
        "        chord = chord[:-1]\n",
        "    chord = chord.replace(\" \", \",\")\n",
        "    return chord\n",
        "\n",
        "def get_number_from_duration(duration):\n",
        "    if duration.startswith(\"<music21.duration.Duration \"):\n",
        "        duration = duration[len(\"<music21.duration.Duration \"):]\n",
        "    if duration.endswith(\">\"):\n",
        "        duration = duration[:-1]\n",
        "    duration = duration.replace(\" \", \",\")\n",
        "    return duration\n",
        "\n",
        "def create_mapper(chords):\n",
        "    pitchnames = sorted(set(str(item) for item in chords))\n",
        "    mapper = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    return mapper\n",
        "\n",
        "def encode_using_mapper(chords, mapper):\n",
        "    encodedsong=[]\n",
        "    for c in chords:\n",
        "        encodedsong.append(mapper[str(c)])\n",
        "\n",
        "    return encodedsong\n",
        "\n",
        "\n",
        "def decode_chords_using_mapper(numbers, mapper):\n",
        "    outputnotes = []\n",
        "    for number in numbers:\n",
        "        outputnotes.append(chord_from_string(get_notes_from_chord(get_key_from_value(number, mapper))))\n",
        "\n",
        "    return outputnotes\n",
        "\n",
        "def combine_chords_with_durations(chords, durations):\n",
        "    combined = []\n",
        "\n",
        "    for i, j in zip(chords, durations):\n",
        "        i = get_notes_from_chord(str(i))\n",
        "        j = get_number_from_duration(str(j))\n",
        "        combined.append(i + ';' + j)\n",
        "\n",
        "    return combined\n",
        "\n",
        "def make_slices(data, slice_length):\n",
        "    for song in tqdm(data):\n",
        "        if len(song) > slice_length:\n",
        "\n",
        "            input = []\n",
        "            output = []\n",
        "            slice = []\n",
        "\n",
        "            for idx, number in enumerate(song):\n",
        "                if idx < slice_length:\n",
        "                    slice.append(number)\n",
        "\n",
        "            input.append(slice.copy())\n",
        "            output.append(song[slice_length])\n",
        "\n",
        "            # Sliding window\n",
        "            for idx, number in enumerate(song):\n",
        "                if idx >= slice_length and (idx + 1) < len(song):\n",
        "                    slice.pop(0)\n",
        "                    slice.append(number)\n",
        "                    input.append(slice.copy())  # Copy is necessary, because of how pointers and lists work in Python\n",
        "                    output.append(song[idx + 1])\n",
        "\n",
        "    return input, output\n",
        "\n",
        "def parse_everything_together(data, slice_length):\n",
        "\n",
        "    notes=[]\n",
        "    input=[]\n",
        "    output=[]\n",
        "    slice = []\n",
        "\n",
        "    for song in tqdm(data):\n",
        "        for number in song:\n",
        "            notes.append(number)\n",
        "    \n",
        "    for idx, note in tqdm(enumerate(notes)):\n",
        "        if idx < slice_length:\n",
        "            slice.append(number)\n",
        "\n",
        "    input.append(slice.copy())\n",
        "    output.append(notes[slice_length])\n",
        "\n",
        "    # Sliding window\n",
        "    for idx, number in tqdm(enumerate(notes)):\n",
        "        if idx >= slice_length and (idx + 1) < len(notes):\n",
        "            slice.pop(0)\n",
        "            slice.append(number)\n",
        "            input.append(slice.copy())  # Copy is necessary, because of how pointers and lists work in Python\n",
        "            output.append(notes[idx + 1])\n",
        "        \n",
        "    return input, output\n",
        "\n",
        "def get_key_from_value(value, dict):\n",
        "    return list(dict.keys())[list(dict.values()).index(value)]\n",
        "\n",
        "def get_notes_from_chord(chord):\n",
        "    if chord.startswith(\"<music21.chord.Chord \"):\n",
        "        chord = chord[len(\"<music21.chord.Chord \"):]\n",
        "    if chord.endswith(\">\"):\n",
        "        chord = chord[:-1]\n",
        "    chord = chord.replace(\" \", \",\")\n",
        "    return chord\n",
        "\n",
        "def get_number_from_duration(duration):\n",
        "    if duration.startswith(\"<music21.duration.Duration \"):\n",
        "        duration = duration[len(\"<music21.duration.Duration \"):]\n",
        "    if duration.endswith(\">\"):\n",
        "        duration = duration[:-1]\n",
        "    duration = duration.replace(\" \", \",\")\n",
        "    return duration\n",
        "\n",
        "def chord_from_string(chordstring):\n",
        "    notes = chordstring.split(\";\")\n",
        "    return chord.Chord(notes)\n",
        "\n",
        "\n",
        "def convert_to_float(frac_str):\n",
        "    #From: https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
        "    try:\n",
        "        return float(frac_str)\n",
        "    except ValueError:\n",
        "        num, denom = frac_str.split('/')\n",
        "        try:\n",
        "            leading, num = num.split(' ')\n",
        "            whole = float(leading)\n",
        "        except ValueError:\n",
        "            whole = 0\n",
        "        frac = float(num) / float(denom)\n",
        "        return whole - frac if whole < 0 else whole + frac\n",
        "\n",
        "#Source: https://github.com/alexissa32/DataScienceMusic\n",
        "def create_midi_without_chords(prediction_output, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    '''\n",
        "    First step:\n",
        "    Only notes, no chords\n",
        "    Static 4/4 beat\n",
        "    Rests\n",
        "    '''\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a rest\n",
        "        if('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def create_midi_without_durations(prediction_output, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    '''\n",
        "    Second step:\n",
        "    Chords and notes\n",
        "    Static 4/4 beat\n",
        "    Rests\n",
        "    '''\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('chord' in pattern):\n",
        "            notes = []\n",
        "            pattern = get_notes_from_chord(pattern)\n",
        "            patternpitches = pattern.split(',')\n",
        "            for current_note in patternpitches:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = target_instrument\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a rest\n",
        "        elif('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def create_midi_with_durations(prediction_output, output_durations, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for i in range(len(prediction_output)):\n",
        "        pattern = prediction_output[i]\n",
        "        duration = get_number_from_duration(output_durations[i])\n",
        "        # pattern is a chord\n",
        "        if ('chord' in pattern):\n",
        "            notes = []\n",
        "            pattern = get_notes_from_chord(pattern)\n",
        "            patternpitches = pattern.split(',')\n",
        "            for current_note in patternpitches:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = target_instrument\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a rest\n",
        "        elif('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += convert_to_float(duration)\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def create_midi_with_embedded_durations(prediction_output, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for i in range(len(prediction_output)):\n",
        "        pattern = prediction_output[i]\n",
        "        splitpattern = pattern.split(\";\")\n",
        "        pattern = splitpattern[0]\n",
        "\n",
        "        duration = get_number_from_duration(splitpattern[1])\n",
        "        # pattern is a rest\n",
        "        if('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a chord\n",
        "        elif (',' in pattern):\n",
        "            notes = []\n",
        "            pattern = get_notes_from_chord(pattern)\n",
        "            patternpitches = pattern.split(',')\n",
        "            for current_note in patternpitches:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = target_instrument\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += convert_to_float(duration)\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def parse_midi_notes_and_durations():\n",
        "    midiparts = []\n",
        "\n",
        "    for file in tqdm(os.listdir(path)):\n",
        "        midi = converter.parse(os.path.join(path, file))\n",
        "\n",
        "        for part in midi.parts:\n",
        "            chords=[]\n",
        "            durations=[]\n",
        "            for element in part.notesAndRests:\n",
        "                if isinstance(element, note.Note):\n",
        "                    chords.append(chord.Chord([element]))\n",
        "                    durations.append(element.duration)\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    chords.append(element)\n",
        "                    durations.append(element.duration)\n",
        "                elif isinstance(element, note.Rest):\n",
        "                    chords.append(element)\n",
        "                    durations.append(element.duration)\n",
        "\n",
        "            if len(chords) > 0:\n",
        "                midiparts.append(MidiPart(file, part.partName, chords, durations))\n",
        "            else:\n",
        "                for voice in part.voices:\n",
        "                    chords=[]\n",
        "                    durations=[]\n",
        "                    for element in voice.notesAndRests:\n",
        "                        if isinstance(element, note.Note):\n",
        "                            chords.append(chord.Chord([element]))\n",
        "                            durations.append(element.duration)\n",
        "                        elif isinstance(element, chord.Chord):\n",
        "                            chords.append(element)\n",
        "                            durations.append(element.duration)\n",
        "                        elif isinstance(element, note.Rest):\n",
        "                            chords.append(element)\n",
        "                            durations.append(element.duration)\n",
        "\n",
        "                    midiparts.append(MidiPart(file, part.partName, chords, durations))\n",
        "\n",
        "    return midiparts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDPW_TEICkSr"
      },
      "source": [
        "# PREPROCESSING SECTION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b1wB3QjCme0"
      },
      "source": [
        "class MidiPart:\n",
        "    def __init__(self, song, instrument, chords, durations):\n",
        "        self.song = song\n",
        "        self.instrument = instrument\n",
        "        self.chords = chords\n",
        "        self.durations = durations\n",
        "\n",
        "\n",
        "path = MIDI_PATH\n",
        "\n",
        "IRON_MAIDEN_INSTRUMENTS = ['Acoustic Guitar', 'Viola', 'Electric Bass', 'Brass', 'Sampler', 'Electric Guitar', 'Piano', 'StringInstrument']\n",
        "\n",
        "SLICE_LEN = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlRVxlEbCotU",
        "outputId": "232138a1-c995-4064-8a60-9234ba1ee835"
      },
      "source": [
        "midiparts = parse_midi_notes_and_durations()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [14:13<00:00,  9.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Xm2bl7CplM"
      },
      "source": [
        "allchords = []\n",
        "alldurations = []\n",
        "\n",
        "TARGET_INSTRUMENT = 'Electric Bass'\n",
        "for i in midiparts:\n",
        "    if i.instrument == TARGET_INSTRUMENT:\n",
        "        if len(i.chords)>0 :\n",
        "            allchords.append(i.chords)\n",
        "            alldurations.append(i.durations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKMjdudnCqn5"
      },
      "source": [
        "assert(len(allchords) == len(alldurations))\n",
        "\n",
        "combined = []\n",
        "for i in range(len(allchords)):\n",
        "    combined.append(combine_chords_with_durations(allchords[i], alldurations[i]))\n",
        "\n",
        "mapperdata = []\n",
        "\n",
        "for i in combined:\n",
        "    for j in i:\n",
        "        mapperdata.append(j)\n",
        "\n",
        "mapper = create_mapper(mapperdata)\n",
        "\n",
        "encoded_data = []\n",
        "\n",
        "for c in combined:\n",
        "    encoded = encode_using_mapper(c, mapper)\n",
        "    encoded_data.append(encoded)\n",
        "\n",
        "restkeysvalues = []\n",
        "for j in mapper.keys():\n",
        "    if ( 'rest' in j):\n",
        "        restkeysvalues.append(mapper[j])\n",
        "\n",
        "cleared_encoded_data=[]\n",
        "\n",
        "for i in range(len(encoded_data)):\n",
        "    if most_frequent(encoded_data[i]) not in restkeysvalues:\n",
        "        cleared_encoded_data.append(encoded_data[i])\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXAfyYc9Cs2f",
        "outputId": "113f9289-8f7c-4eec-aade-2f99812cd0cc"
      },
      "source": [
        "#Creating the input data\n",
        "\n",
        "input, output = parse_everything_together(cleared_encoded_data, SLICE_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [00:00<00:00, 8069.93it/s]\n",
            "158198it [00:00, 2855970.59it/s]\n",
            "158198it [00:00, 739969.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWQx75XPCt3h"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "outputcnt = Counter(output)\n",
        "\n",
        "function_like_array=[]\n",
        "for val in outputcnt.values():\n",
        "    function_like_array.append(val)\n",
        "\n",
        "function_like_array.sort()\n",
        "\n",
        "outliers = []\n",
        "OUTLIER_CONSTANT = 40\n",
        "\n",
        "for i in outputcnt.keys():\n",
        "    if outputcnt[i] < OUTLIER_CONSTANT:\n",
        "        outliers.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrgS06MOCvEr"
      },
      "source": [
        "#Because I don't want to mess up my inputs and outputs, I test their lengths before and after the outlier filtering.\n",
        "assert(len(input) == len(output))\n",
        "\n",
        "newinput=[]\n",
        "newoutput=[]\n",
        "\n",
        "for i in range(len(output)):\n",
        "    if(output[i] not in outliers):\n",
        "        newinput.append(input[i])\n",
        "        newoutput.append(output[i])\n",
        "\n",
        "input = newinput\n",
        "output = newoutput\n",
        "\n",
        "assert(len(input) == len(output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqrdwosCwPn"
      },
      "source": [
        "#However, this outlier filtering made things complicated. Now I have to make a new mapper, so that i won't end up with output classes containing 0 elements.\n",
        "\n",
        "mapper_list = [] #Idx of the mapper list is the new value, the element is the old value.\n",
        "new_output_elements = set(output)\n",
        "\n",
        "for i in new_output_elements:\n",
        "    mapper_list.append(i)\n",
        "\n",
        "newoutput = []\n",
        "\n",
        "for i in output:\n",
        "    newoutput.append(mapper_list.index(i))\n",
        "\n",
        "output = newoutput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqaL4N9eCxCZ"
      },
      "source": [
        "input = np.reshape(np.asarray(input), (len(input), SLICE_LEN, 1))\n",
        "output=np.asarray(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv2INnZOCx3O",
        "outputId": "ee5d3da3-eebd-41a2-fae6-4ea6e2a39e4c"
      },
      "source": [
        "SEED = 54\n",
        "#np.random.seed(SEED)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(input, output, test_size=0.01, random_state=SEED)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "startidx = np.random.randint(0, len(X_test)-1)\n",
        "starting_slice = X_test[startidx]\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "print(startidx)\n",
        "print(starting_slice)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(121952, 20, 1) (30489, 20, 1) (1540, 20, 1) (121952,) (30489,) (1540,)\n",
            "417\n",
            "[[748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [748]\n",
            " [217]\n",
            " [217]\n",
            " [217]\n",
            " [217]\n",
            " [309]\n",
            " [398]\n",
            " [708]\n",
            " [708]\n",
            " [708]\n",
            " [  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mr4do7ObAOn"
      },
      "source": [
        "# MODEL TRAINING SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txOwScdfGCoS"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# DATA GENERATOR\n",
        "NUM_CLASSES = to_categorical(Y_train).shape[1]\n",
        "SLICE_SIZE = SLICE_LEN\n",
        "\n",
        "class MyDatagen(Sequence):\n",
        "  def __init__(self, list_IDs, batch_size=16, dim=(SLICE_SIZE), shuffle=True, validation=False):\n",
        "    'Initialization'\n",
        "    self.dim = dim\n",
        "    self.batch_size = batch_size\n",
        "    self.list_IDs = list_IDs\n",
        "    self.shuffle = shuffle\n",
        "    self.validation=validation\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Generate indexes of the batch\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "    # Generate data\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "      #Updates indexes after each epoch\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    #Generates data containing batch_size samples\n",
        "    if self.validation:\n",
        "      X = np.empty((self.batch_size, self.dim, 1))\n",
        "      y = np.empty((self.batch_size, NUM_CLASSES))\n",
        "\n",
        "      # Generate data\n",
        "      for i, ID in enumerate(list_IDs_temp):\n",
        "        X[i] = X_val[ID]\n",
        "\n",
        "        y[i] = to_categorical(Y_val[ID], num_classes=NUM_CLASSES)\n",
        "\n",
        "      return X, y\n",
        "    else:\n",
        "      X = np.empty((self.batch_size, self.dim, 1))\n",
        "      y = np.empty((self.batch_size, NUM_CLASSES))\n",
        "\n",
        "      # Generate data\n",
        "      for i, ID in enumerate(list_IDs_temp):\n",
        "        X[i] = X_train[ID]\n",
        "\n",
        "        y[i] = to_categorical(Y_train[ID], num_classes=NUM_CLASSES)\n",
        "\n",
        "      return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8_sRgmI-mT"
      },
      "source": [
        "MODEL_NAME = \"Transformer_bass_1\"\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/MLFolder/Onlab/modelsaves/\"\n",
        "\n",
        "TBPATH = \"/content/tblogs/\"+MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Jc9A39bLzY"
      },
      "source": [
        "#Before creating the neural network, I define some important callbacks\n",
        "\n",
        "tb = TensorBoard(log_dir = TBPATH, write_images=True, histogram_freq=1)\n",
        "\n",
        "plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00005, verbose=1)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience = 5, restore_best_weights = True, verbose=1)\n",
        "\n",
        "callbacks = [plateau, es, tb]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJGAIgJfyaeu"
      },
      "source": [
        "#CONSTANTS:\n",
        "\n",
        "EMBEDDING_DIM = 256\n",
        "encoder_layers = 1\n",
        "decoder_layers = 1\n",
        "dropout_rate = 0.1\n",
        "layernorm_epsilon = 1e-6\n",
        "num_heads = 4\n",
        "key_dim = 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LImJHAXeRhrO"
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "import math as m\n",
        "\n",
        "#source: https://github.com/jason9693/MusicTransformer-tensorflow2.0\n",
        "class DynamicPositionEmbedding(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        embedding_dim = EMBEDDING_DIM\n",
        "        max_seq=2048\n",
        "        embed_sinusoid_list = np.array([[\n",
        "            [\n",
        "                m.sin(\n",
        "                    pos * m.exp(-m.log(10000) * i/embedding_dim) *\n",
        "                    m.exp(m.log(10000)/embedding_dim * (i % 2)) + 0.5 * m.pi * (i % 2)\n",
        "                )\n",
        "                for i in range(embedding_dim)\n",
        "            ]\n",
        "            for pos in range(max_seq)\n",
        "        ]])\n",
        "        self.positional_embedding = tf.constant(embed_sinusoid_list, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.add(inputs, self.positional_embedding[:,:inputs.shape[1],:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5kNt8Nph9_J"
      },
      "source": [
        "def make_encoder_block(x):\n",
        "    #attn_out = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout_rate)(x,x)\n",
        "    attn_out = Attention()([x,x])\n",
        "    lnorm = LayerNormalization(epsilon=layernorm_epsilon)(attn_out+x)\n",
        "    x = Dense(EMBEDDING_DIM // 2, activation='relu')(lnorm)\n",
        "    x = Dense(EMBEDDING_DIM)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    #x = LayerNormalization(epsilon=layernorm_epsilon)(lnorm+x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sIWWkFU4ZBf"
      },
      "source": [
        "def make_decoder_block(x, encoder_out):\n",
        "    #attn_out = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout_rate)(x,x)\n",
        "    attn_out = Attention()([x,x])\n",
        "    x = LayerNormalization(epsilon=layernorm_epsilon)(attn_out+x)\n",
        "    #attn_out = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout_rate)(x, encoder_out, encoder_out)\n",
        "    attn_out = Attention()([x,x])\n",
        "    lnorm = LayerNormalization(epsilon=layernorm_epsilon)(attn_out+x)\n",
        "    x = Dense(EMBEDDING_DIM // 2, activation='relu')(lnorm)\n",
        "    x = Dense(EMBEDDING_DIM)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    #x = LayerNormalization(epsilon=layernorm_epsilon)(lnorm+x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbZ73wx8bN2u",
        "outputId": "8bb5db26-fd71-4021-8f6e-c536b71bbb9b"
      },
      "source": [
        "#I create the neural network model here.\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Attention\n",
        "from tensorflow.keras.layers import Embedding, Reshape, Dropout\n",
        "from tensorflow.keras.layers import Input, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(SLICE_LEN,1))\n",
        "x = Embedding(len(mapper), EMBEDDING_DIM, input_length=SLICE_LEN)(input_layer)\n",
        "x = Reshape((SLICE_LEN, EMBEDDING_DIM))(x)\n",
        "x = DynamicPositionEmbedding()(x)\n",
        "enc_out = make_encoder_block(x)\n",
        "\n",
        "for i in range(encoder_layers-1):\n",
        "    enc_out = make_encoder_block(enc_out)\n",
        "\n",
        "for i in range(decoder_layers):\n",
        "    x = make_decoder_block(x, enc_out)\n",
        "\n",
        "x = Flatten()(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(input_layer, output)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "training_gen=MyDatagen(range(X_train.shape[0]), dim = SLICE_LEN, batch_size=16)\n",
        "val_gen=MyDatagen(range(X_val.shape[0]), dim = SLICE_LEN, batch_size=16, validation=True)\n",
        "\n",
        "model.fit(training_gen, epochs=10000, validation_data=val_gen, callbacks=callbacks)\n",
        "\n",
        "model.evaluate(X_test, to_categorical(Y_test, num_classes=NUM_CLASSES))\n",
        "\n",
        "model.save(MODEL_SAVE_PATH + MODEL_NAME + \".h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 1.7989 - accuracy: 0.5843 - val_loss: 1.5360 - val_accuracy: 0.6344 - lr: 0.0010\n",
            "Epoch 2/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.4592 - accuracy: 0.6499 - val_loss: 1.5111 - val_accuracy: 0.6430 - lr: 0.0010\n",
            "Epoch 3/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.3733 - accuracy: 0.6665 - val_loss: 1.4127 - val_accuracy: 0.6619 - lr: 0.0010\n",
            "Epoch 4/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.3136 - accuracy: 0.6802 - val_loss: 1.3602 - val_accuracy: 0.6797 - lr: 0.0010\n",
            "Epoch 5/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.2636 - accuracy: 0.6885 - val_loss: 1.3327 - val_accuracy: 0.6845 - lr: 0.0010\n",
            "Epoch 6/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.2230 - accuracy: 0.6990 - val_loss: 1.3099 - val_accuracy: 0.6829 - lr: 0.0010\n",
            "Epoch 7/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.1899 - accuracy: 0.7056 - val_loss: 1.2884 - val_accuracy: 0.6921 - lr: 0.0010\n",
            "Epoch 8/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 1.1578 - accuracy: 0.7115 - val_loss: 1.2592 - val_accuracy: 0.6986 - lr: 0.0010\n",
            "Epoch 9/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 1.1297 - accuracy: 0.7196 - val_loss: 1.2598 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 10/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.1022 - accuracy: 0.7250 - val_loss: 1.2244 - val_accuracy: 0.7140 - lr: 0.0010\n",
            "Epoch 11/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.0695 - accuracy: 0.7306 - val_loss: 1.2034 - val_accuracy: 0.7173 - lr: 0.0010\n",
            "Epoch 12/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.0440 - accuracy: 0.7375 - val_loss: 1.1950 - val_accuracy: 0.7137 - lr: 0.0010\n",
            "Epoch 13/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 1.0184 - accuracy: 0.7430 - val_loss: 1.1741 - val_accuracy: 0.7271 - lr: 0.0010\n",
            "Epoch 14/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 0.9942 - accuracy: 0.7492 - val_loss: 1.1666 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 15/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 0.9743 - accuracy: 0.7531 - val_loss: 1.1574 - val_accuracy: 0.7285 - lr: 0.0010\n",
            "Epoch 16/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 0.9496 - accuracy: 0.7587 - val_loss: 1.1330 - val_accuracy: 0.7318 - lr: 0.0010\n",
            "Epoch 17/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.9295 - accuracy: 0.7639 - val_loss: 1.1317 - val_accuracy: 0.7353 - lr: 0.0010\n",
            "Epoch 18/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.9111 - accuracy: 0.7675 - val_loss: 1.1153 - val_accuracy: 0.7441 - lr: 0.0010\n",
            "Epoch 19/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.8955 - accuracy: 0.7715 - val_loss: 1.1086 - val_accuracy: 0.7445 - lr: 0.0010\n",
            "Epoch 20/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.8784 - accuracy: 0.7752 - val_loss: 1.1024 - val_accuracy: 0.7484 - lr: 0.0010\n",
            "Epoch 21/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.8671 - accuracy: 0.7788 - val_loss: 1.1066 - val_accuracy: 0.7477 - lr: 0.0010\n",
            "Epoch 22/10000\n",
            "7617/7622 [============================>.] - ETA: 0s - loss: 0.8545 - accuracy: 0.7810\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 0.8547 - accuracy: 0.7810 - val_loss: 1.1040 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 23/10000\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 0.7306 - accuracy: 0.8146 - val_loss: 1.0332 - val_accuracy: 0.7738 - lr: 2.0000e-04\n",
            "Epoch 24/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.7051 - accuracy: 0.8204 - val_loss: 1.0356 - val_accuracy: 0.7775 - lr: 2.0000e-04\n",
            "Epoch 25/10000\n",
            "7619/7622 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.8235\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "7622/7622 [==============================] - 48s 6ms/step - loss: 0.6934 - accuracy: 0.8234 - val_loss: 1.0513 - val_accuracy: 0.7780 - lr: 2.0000e-04\n",
            "Epoch 26/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.6634 - accuracy: 0.8308 - val_loss: 1.0381 - val_accuracy: 0.7824 - lr: 5.0000e-05\n",
            "Epoch 27/10000\n",
            "7622/7622 [==============================] - 47s 6ms/step - loss: 0.6588 - accuracy: 0.8326 - val_loss: 1.0430 - val_accuracy: 0.7825 - lr: 5.0000e-05\n",
            "Epoch 28/10000\n",
            "7616/7622 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.8333Restoring model weights from the end of the best epoch: 23.\n",
            "7622/7622 [==============================] - 49s 6ms/step - loss: 0.6558 - accuracy: 0.8334 - val_loss: 1.0465 - val_accuracy: 0.7825 - lr: 5.0000e-05\n",
            "Epoch 00028: early stopping\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.0623 - accuracy: 0.7805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SKEQ422hZnR",
        "outputId": "4986d0c0-e5da-4f55-d42b-5bdb1e4ee8eb"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1937509"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}