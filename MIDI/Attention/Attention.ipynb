{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "b_3sHSkE7ei3"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UQYeMFH7if3"
      },
      "source": [
        "# IMPORT SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ZY6uqc6PCw",
        "outputId": "5e2580f3-4e7c-4402-c0be-29c40083be61"
      },
      "source": [
        "!pip install --upgrade music21==6.7.1\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout\n",
        "%load_ext tensorboard \n",
        "from tensorboard import notebook\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting music21==6.7.1\n",
            "  Downloading music21-6.7.1.tar.gz (19.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from music21==6.7.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from music21==6.7.1) (1.0.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from music21==6.7.1) (8.10.0)\n",
            "Collecting webcolors\n",
            "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: music21\n",
            "  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for music21: filename=music21-6.7.1-py3-none-any.whl size=21941721 sha256=9e263e65d6077dae60518bdf57a4e6b13454c12505375b82f0aac460e76717c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/44/61/90e4e65262ca1b4d9f707527b540729ce3f64e00fc6b38d54c\n",
            "Successfully built music21\n",
            "Installing collected packages: webcolors, music21\n",
            "  Attempting uninstall: music21\n",
            "    Found existing installation: music21 5.5.0\n",
            "    Uninstalling music21-5.5.0:\n",
            "      Successfully uninstalled music21-5.5.0\n",
            "Successfully installed music21-6.7.1 webcolors-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE-M7nPx7cm9",
        "outputId": "449fd2ef-55e9-42a3-efcc-ed7dd39dbeda"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "MIDI_PATH=\"/content/drive/My Drive/MLFolder/Onlab/MIDI_Iron_Maiden/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRrSLZ2W7ddN",
        "outputId": "6c757305-c7e2-4c68-d36e-812e203e0c61"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov  7 10:02:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_3sHSkE7ei3"
      },
      "source": [
        "# UTILITY FUNCTIONS SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E38xCZCS7lGE"
      },
      "source": [
        "def most_frequent(paramlist): \n",
        "    #https://www.geeksforgeeks.org/python-find-most-frequent-element-in-a-list/\n",
        "    counter = 0\n",
        "    num = paramlist[0] \n",
        "      \n",
        "    for i in paramlist: \n",
        "        curr_frequency = paramlist.count(i) \n",
        "        if(curr_frequency> counter): \n",
        "            counter = curr_frequency \n",
        "            num = i \n",
        "  \n",
        "    return num \n",
        "\n",
        "def get_notes_from_chord(chord):\n",
        "    if chord.startswith(\"<music21.chord.Chord \"):\n",
        "        chord = chord[len(\"<music21.chord.Chord \"):]\n",
        "    if chord.endswith(\">\"):\n",
        "        chord = chord[:-1]\n",
        "    chord = chord.replace(\" \", \",\")\n",
        "    return chord\n",
        "\n",
        "def get_number_from_duration(duration):\n",
        "    if duration.startswith(\"<music21.duration.Duration \"):\n",
        "        duration = duration[len(\"<music21.duration.Duration \"):]\n",
        "    if duration.endswith(\">\"):\n",
        "        duration = duration[:-1]\n",
        "    duration = duration.replace(\" \", \",\")\n",
        "    return duration\n",
        "\n",
        "def create_mapper(chords):\n",
        "    pitchnames = sorted(set(str(item) for item in chords))\n",
        "    mapper = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    return mapper\n",
        "\n",
        "def encode_using_mapper(chords, mapper):\n",
        "    encodedsong=[]\n",
        "    for c in chords:\n",
        "        encodedsong.append(mapper[str(c)])\n",
        "\n",
        "    return encodedsong\n",
        "\n",
        "\n",
        "def decode_chords_using_mapper(numbers, mapper):\n",
        "    outputnotes = []\n",
        "    for number in numbers:\n",
        "        outputnotes.append(chord_from_string(get_notes_from_chord(get_key_from_value(number, mapper))))\n",
        "\n",
        "    return outputnotes\n",
        "\n",
        "def combine_chords_with_durations(chords, durations):\n",
        "    combined = []\n",
        "\n",
        "    for i, j in zip(chords, durations):\n",
        "        i = get_notes_from_chord(str(i))\n",
        "        j = get_number_from_duration(str(j))\n",
        "        combined.append(i + ';' + j)\n",
        "\n",
        "    return combined\n",
        "\n",
        "def make_slices(data, slice_length):\n",
        "    for song in tqdm(data):\n",
        "        if len(song) > slice_length:\n",
        "\n",
        "            input = []\n",
        "            output = []\n",
        "            slice = []\n",
        "\n",
        "            for idx, number in enumerate(song):\n",
        "                if idx < slice_length:\n",
        "                    slice.append(number)\n",
        "\n",
        "            input.append(slice.copy())\n",
        "            output.append(song[slice_length])\n",
        "\n",
        "            # Sliding window\n",
        "            for idx, number in enumerate(song):\n",
        "                if idx >= slice_length and (idx + 1) < len(song):\n",
        "                    slice.pop(0)\n",
        "                    slice.append(number)\n",
        "                    input.append(slice.copy())  # Copy is necessary, because of how pointers and lists work in Python\n",
        "                    output.append(song[idx + 1])\n",
        "\n",
        "    return input, output\n",
        "\n",
        "def parse_everything_together(data, slice_length):\n",
        "\n",
        "    notes=[]\n",
        "    input=[]\n",
        "    output=[]\n",
        "    slice = []\n",
        "\n",
        "    for song in tqdm(data):\n",
        "        for number in song:\n",
        "            notes.append(number)\n",
        "    \n",
        "    for idx, note in tqdm(enumerate(notes)):\n",
        "        if idx < slice_length:\n",
        "            slice.append(number)\n",
        "\n",
        "    input.append(slice.copy())\n",
        "    output.append(notes[slice_length])\n",
        "\n",
        "    # Sliding window\n",
        "    for idx, number in tqdm(enumerate(notes)):\n",
        "        if idx >= slice_length and (idx + 1) < len(notes):\n",
        "            slice.pop(0)\n",
        "            slice.append(number)\n",
        "            input.append(slice.copy())  # Copy is necessary, because of how pointers and lists work in Python\n",
        "            output.append(notes[idx + 1])\n",
        "        \n",
        "    return input, output\n",
        "\n",
        "def get_key_from_value(value, dict):\n",
        "    return list(dict.keys())[list(dict.values()).index(value)]\n",
        "\n",
        "def get_notes_from_chord(chord):\n",
        "    if chord.startswith(\"<music21.chord.Chord \"):\n",
        "        chord = chord[len(\"<music21.chord.Chord \"):]\n",
        "    if chord.endswith(\">\"):\n",
        "        chord = chord[:-1]\n",
        "    chord = chord.replace(\" \", \",\")\n",
        "    return chord\n",
        "\n",
        "def get_number_from_duration(duration):\n",
        "    if duration.startswith(\"<music21.duration.Duration \"):\n",
        "        duration = duration[len(\"<music21.duration.Duration \"):]\n",
        "    if duration.endswith(\">\"):\n",
        "        duration = duration[:-1]\n",
        "    duration = duration.replace(\" \", \",\")\n",
        "    return duration\n",
        "\n",
        "def chord_from_string(chordstring):\n",
        "    notes = chordstring.split(\";\")\n",
        "    return chord.Chord(notes)\n",
        "\n",
        "\n",
        "def convert_to_float(frac_str):\n",
        "    #From: https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
        "    try:\n",
        "        return float(frac_str)\n",
        "    except ValueError:\n",
        "        num, denom = frac_str.split('/')\n",
        "        try:\n",
        "            leading, num = num.split(' ')\n",
        "            whole = float(leading)\n",
        "        except ValueError:\n",
        "            whole = 0\n",
        "        frac = float(num) / float(denom)\n",
        "        return whole - frac if whole < 0 else whole + frac\n",
        "\n",
        "#Source: https://github.com/alexissa32/DataScienceMusic\n",
        "def create_midi_without_chords(prediction_output, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    '''\n",
        "    First step:\n",
        "    Only notes, no chords\n",
        "    Static 4/4 beat\n",
        "    Rests\n",
        "    '''\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a rest\n",
        "        if('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def create_midi_without_durations(prediction_output, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    '''\n",
        "    Second step:\n",
        "    Chords and notes\n",
        "    Static 4/4 beat\n",
        "    Rests\n",
        "    '''\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('chord' in pattern):\n",
        "            notes = []\n",
        "            pattern = get_notes_from_chord(pattern)\n",
        "            patternpitches = pattern.split(',')\n",
        "            for current_note in patternpitches:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = target_instrument\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a rest\n",
        "        elif('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def create_midi_with_durations(prediction_output, output_durations, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for i in range(len(prediction_output)):\n",
        "        pattern = prediction_output[i]\n",
        "        duration = get_number_from_duration(output_durations[i])\n",
        "        # pattern is a chord\n",
        "        if ('chord' in pattern):\n",
        "            notes = []\n",
        "            pattern = get_notes_from_chord(pattern)\n",
        "            patternpitches = pattern.split(',')\n",
        "            for current_note in patternpitches:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = target_instrument\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a rest\n",
        "        elif('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += convert_to_float(duration)\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def create_midi_with_embedded_durations(prediction_output, target_instrument = instrument.Piano(), filename = 'test_output.mid'):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for i in range(len(prediction_output)):\n",
        "        pattern = prediction_output[i]\n",
        "        splitpattern = pattern.split(\";\")\n",
        "        pattern = splitpattern[0]\n",
        "\n",
        "        duration = get_number_from_duration(splitpattern[1])\n",
        "        # pattern is a rest\n",
        "        if('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = target_instrument #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a chord\n",
        "        elif (',' in pattern):\n",
        "            notes = []\n",
        "            pattern = get_notes_from_chord(pattern)\n",
        "            patternpitches = pattern.split(',')\n",
        "            for current_note in patternpitches:\n",
        "                new_note = note.Note(current_note)\n",
        "                new_note.storedInstrument = target_instrument\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = target_instrument\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += convert_to_float(duration)\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "\n",
        "def parse_midi_notes_and_durations():\n",
        "    midiparts = []\n",
        "\n",
        "    for file in tqdm(os.listdir(path)):\n",
        "        midi = converter.parse(os.path.join(path, file))\n",
        "\n",
        "        for part in midi.parts:\n",
        "            chords=[]\n",
        "            durations=[]\n",
        "            for element in part.notesAndRests:\n",
        "                if isinstance(element, note.Note):\n",
        "                    chords.append(chord.Chord([element]))\n",
        "                    durations.append(element.duration)\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    chords.append(element)\n",
        "                    durations.append(element.duration)\n",
        "                elif isinstance(element, note.Rest):\n",
        "                    chords.append(element)\n",
        "                    durations.append(element.duration)\n",
        "\n",
        "            if len(chords) > 0:\n",
        "                midiparts.append(MidiPart(file, part.partName, chords, durations))\n",
        "            else:\n",
        "                for voice in part.voices:\n",
        "                    chords=[]\n",
        "                    durations=[]\n",
        "                    for element in voice.notesAndRests:\n",
        "                        if isinstance(element, note.Note):\n",
        "                            chords.append(chord.Chord([element]))\n",
        "                            durations.append(element.duration)\n",
        "                        elif isinstance(element, chord.Chord):\n",
        "                            chords.append(element)\n",
        "                            durations.append(element.duration)\n",
        "                        elif isinstance(element, note.Rest):\n",
        "                            chords.append(element)\n",
        "                            durations.append(element.duration)\n",
        "\n",
        "                    midiparts.append(MidiPart(file, part.partName, chords, durations))\n",
        "\n",
        "    return midiparts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDPW_TEICkSr"
      },
      "source": [
        "# PREPROCESSING SECTION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b1wB3QjCme0"
      },
      "source": [
        "class MidiPart:\n",
        "    def __init__(self, song, instrument, chords, durations):\n",
        "        self.song = song\n",
        "        self.instrument = instrument\n",
        "        self.chords = chords\n",
        "        self.durations = durations\n",
        "\n",
        "\n",
        "path = MIDI_PATH\n",
        "\n",
        "IRON_MAIDEN_INSTRUMENTS = ['Acoustic Guitar', 'Viola', 'Electric Bass', 'Brass', 'Sampler', 'Electric Guitar', 'Piano', 'StringInstrument']\n",
        "\n",
        "SLICE_LEN = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlRVxlEbCotU",
        "outputId": "770cd6e6-d423-411a-b7cb-d6468f265932"
      },
      "source": [
        "midiparts = parse_midi_notes_and_durations()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [13:50<00:00,  8.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Xm2bl7CplM"
      },
      "source": [
        "allchords = []\n",
        "alldurations = []\n",
        "\n",
        "TARGET_INSTRUMENT = 'Electric Guitar'\n",
        "for i in midiparts:\n",
        "    if i.instrument == TARGET_INSTRUMENT:\n",
        "        if len(i.chords)>0 :\n",
        "            allchords.append(i.chords)\n",
        "            alldurations.append(i.durations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKMjdudnCqn5"
      },
      "source": [
        "#RUN THIS CELL IF YOU WANT NOTES TO HAVE DURATIONS\n",
        "\n",
        "assert(len(allchords) == len(alldurations))\n",
        "\n",
        "combined = []\n",
        "for i in range(len(allchords)):\n",
        "    combined.append(combine_chords_with_durations(allchords[i], alldurations[i]))\n",
        "\n",
        "mapperdata = []\n",
        "\n",
        "for i in combined:\n",
        "    for j in i:\n",
        "        mapperdata.append(j)\n",
        "\n",
        "mapper = create_mapper(mapperdata)\n",
        "\n",
        "encoded_data = []\n",
        "\n",
        "for c in combined:\n",
        "    encoded = encode_using_mapper(c, mapper)\n",
        "    encoded_data.append(encoded)\n",
        "\n",
        "restkeysvalues = []\n",
        "for j in mapper.keys():\n",
        "    if ( 'rest' in j):\n",
        "        restkeysvalues.append(mapper[j])\n",
        "\n",
        "cleared_encoded_data=[]\n",
        "\n",
        "for i in range(len(encoded_data)):\n",
        "    if most_frequent(encoded_data[i]) not in restkeysvalues:\n",
        "        cleared_encoded_data.append(encoded_data[i])\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXAfyYc9Cs2f",
        "outputId": "4fd2a4eb-f33c-44d2-8e97-5730edd331fe"
      },
      "source": [
        "#Creating the input data\n",
        "\n",
        "input, output = parse_everything_together(cleared_encoded_data, SLICE_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 408/408 [00:00<00:00, 21330.96it/s]\n",
            "240815it [00:00, 2870581.21it/s]\n",
            "240815it [00:00, 730428.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "XWQx75XPCt3h",
        "outputId": "669cace3-277b-4398-d871-2faa09fa8a76"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "outputcnt = Counter(output)\n",
        "plt.bar(outputcnt.keys(), outputcnt.values())\n",
        "plt.show()\n",
        "\n",
        "function_like_array=[]\n",
        "for val in outputcnt.values():\n",
        "    function_like_array.append(val)\n",
        "\n",
        "function_like_array.sort()\n",
        "plt.plot(function_like_array)\n",
        "\n",
        "\n",
        "\n",
        "outliers = []\n",
        "OUTLIER_CONSTANT = 40\n",
        "\n",
        "for i in outputcnt.keys():\n",
        "    if outputcnt[i] < OUTLIER_CONSTANT:\n",
        "        outliers.append(i)\n",
        "\n",
        "print(outliers)\n",
        "print(len(outliers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 394,
              "height": 248
            },
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1963, 2553, 1966, 2490, 1626, 1238, 1235, 2952, 1248, 2285, 3271, 3709, 902, 1041, 1033, 1752, 804, 927, 1949, 236, 2889, 956, 1835, 1419, 3809, 1239, 2636, 2424, 1303, 812, 821, 2787, 3591, 256, 99, 302, 40, 95, 518, 162, 574, 2900, 97, 430, 167, 2831, 2850, 2164, 2177, 1352, 520, 369, 1769, 594, 600, 406, 2816, 545, 549, 50, 3777, 251, 1814, 2823, 1398, 3130, 3121, 2235, 2238, 929, 2829, 2833, 2847, 2812, 1381, 3700, 3701, 3037, 3038, 2038, 873, 874, 3702, 2458, 1873, 623, 1579, 1878, 94, 3386, 2231, 67, 1032, 3218, 1807, 1654, 3528, 1337, 1782, 253, 1131, 3290, 3277, 3732, 2523, 349, 593, 404, 146, 932, 378, 111, 417, 228, 537, 13, 39, 1747, 225, 536, 171, 415, 148, 2535, 1278, 361, 247, 1121, 2922, 2361, 1508, 1308, 3769, 2897, 1823, 959, 2898, 2646, 867, 3680, 2007, 3284, 909, 1815, 2226, 1078, 1065, 3310, 968, 1524, 3082, 561, 2905, 2522, 1401, 1385, 1387, 2895, 1388, 1206, 2570, 2121, 724, 307, 2394, 110, 125, 3245, 3681, 1023, 3540, 693, 779, 767, 1656, 1497, 1493, 1739, 2064, 1957, 3759, 2293, 3183, 1175, 700, 477, 2401, 2390, 1926, 2405, 2404, 3811, 3798, 2278, 2025, 2022, 1729, 3529, 3551, 1756, 2538, 2265, 3581, 427, 1003, 3468, 997, 995, 1563, 1559, 1922, 1557, 719, 1005, 1681, 706, 3293, 2290, 2311, 3307, 3197, 3196, 1002, 2260, 2315, 3306, 1076, 3799, 1072, 1083, 181, 1016, 2630, 297, 2445, 776, 2429, 3569, 3570, 1168, 1167, 2931, 1923, 2362, 2366, 3522, 3689, 1367, 1368, 2856, 3752, 3444, 670, 1620, 2544, 943, 2870, 2873, 3717, 908, 2203, 836, 367, 2842, 2841, 3585, 377, 2171, 651, 657, 468, 1289, 363, 2557, 2556, 673, 2807, 1886, 1549, 3406, 3034, 3033, 3032, 3407, 1722, 3647, 290, 3517, 3036, 2422, 3344, 3519, 1020, 3513, 2128, 3532, 1028, 30, 3435, 1954, 3351, 3443, 1133, 531, 2236, 3805, 3815, 801, 2233, 1066, 1021, 3693, 69, 31, 2369, 429, 655, 52, 118, 3437, 1713, 1705, 1709, 761, 2643, 1242, 1614, 1714, 3021, 871, 2605, 2436, 2610, 1804, 1817, 923, 2208, 3795, 2890, 961, 3125, 3131, 2560, 1616, 2792, 2157, 990, 1031, 2519, 2904, 3314, 3810, 3808, 1780, 3256, 1781, 3807, 1843, 1081, 2220, 1783, 1340, 845, 3598, 1433, 1429, 964, 2244, 1741, 2977, 1246, 3691, 855, 3611, 3003, 2572, 884, 3026, 2442, 3657, 1618, 1610, 660, 3583, 2641, 3025, 2689, 1492, 3723, 138, 79, 471, 2719, 2718, 3095, 3040, 3060, 1195, 1296, 2826, 2187, 80, 383, 435, 2521, 77, 482, 1271, 1965, 3586, 2528, 2529, 3039, 55, 45, 329, 2159, 143, 1645, 1767, 3596, 3590, 479, 1730, 278, 12, 1961, 204, 295, 2381, 2363, 1853, 1550, 1915, 2331, 1548, 2716, 631, 2839, 2321, 1854, 1449, 328, 3490, 1222, 1672, 1671, 1754, 2329, 1172, 269, 333, 36, 433, 2845, 548, 169, 2797, 2814, 3491, 3079, 1314, 3496, 735, 24, 490, 2377, 2365, 465, 332, 275, 23, 3778, 3767, 1728, 2819, 1407, 2809, 352, 1280, 1286, 1123, 1964, 411, 401, 299, 514, 2524, 189, 201, 126, 507, 3462, 512, 2836, 3494, 3433, 777, 2648, 2047, 2754, 3721, 3062, 2751, 2048, 1328, 1778, 831, 1326, 3719, 2757, 3066, 2758, 2176, 3720, 2052, 829, 828, 1325, 3724, 3064, 2054, 2455, 1142, 1623, 499, 506, 277, 128, 605, 589, 505, 1247, 1701, 1708, 2973, 2748, 817, 3699, 3623, 875, 3704, 1757, 1396, 936, 2182, 250, 1064, 3803, 3308, 3305, 370, 3206, 2087, 3267, 1641, 2036, 3269, 296, 2068, 243, 2078, 2337, 2650, 2651, 2661, 3053, 2072, 2071, 2037, 2604, 2692, 2335, 1198, 2120, 714, 1153, 1157, 1393, 2891, 1392, 3018, 1697, 2364, 258, 2368, 2502, 38, 11, 1223, 387, 2980, 260, 530, 3584, 2832, 2474, 2967, 1884, 1580, 2478, 2408, 3043, 3044, 2710, 1458, 1460, 2803, 2834, 2794, 1585, 2438, 1913, 1928, 1976, 336, 1430, 2738, 2763, 2774, 2782, 1837, 2953, 1507, 1510, 2990, 2434, 1975, 1973, 3578, 2540, 173, 213, 224, 2691, 2966, 3042, 3035, 2409, 2968, 183, 29, 1034, 462, 1283, 174, 222, 1462, 1463, 1693, 2804, 2820, 2818, 3086, 2077, 2378, 1478, 1480, 2992, 522, 2979, 351, 3568, 523, 3565, 2805, 2796, 3750, 3763, 3367, 3696, 3695, 3270, 3369, 3697, 3329, 2307, 3294, 3243, 2270, 2268, 3242, 2271, 1484, 3387, 3383, 3385, 2277, 3368, 3318, 3236, 2407, 2411, 1547, 1898, 2406, 1635, 2412, 621, 3287, 2292, 2295, 3239, 3288, 1740, 3365, 3694, 3366, 1062, 346, 2286, 2306, 2166, 1841, 3439, 2395, 2943, 1839, 1844, 1840, 3312, 246, 1912, 48, 773, 3194, 1716, 241, 495, 641, 1649, 2844, 3165, 3212, 1958, 2169, 2178, 3164, 3214, 1312, 1770, 3577, 668, 2800, 1299, 1743, 3564, 648, 2699, 1732, 671, 2141, 3450, 662, 663, 3160, 1955, 3582, 595, 3448, 3446, 3449, 463, 3441, 649, 2146, 572, 2237, 2056, 2174, 1653, 2229, 172, 3438, 498, 563, 1748, 578, 464, 3772, 394, 221, 179, 340, 1932, 2469, 2472, 3202, 3204, 3205, 3203, 203, 1221, 741, 2023, 1217, 2685, 853, 2027, 3538, 1669, 3489, 737, 2464, 2462, 730, 3634, 2461, 2465, 2463, 2680, 3143, 3142, 1883, 91, 2508, 1904, 1544, 1542, 2783, 1220, 3144, 2483, 1584, 2457, 1872, 1574, 2359, 740, 2693, 682, 1324, 1155, 2471, 3705, 624, 3405, 2092, 2323, 3459, 2324, 3148, 2470, 1224, 1219, 1218, 731, 1575, 632, 876, 3419, 3620, 2325, 2678, 3145, 3147, 2510, 3146, 2507, 3706, 1252, 3002, 3221, 2083, 3046, 2450, 1591, 3421, 3426, 2328, 2327, 3409, 3408, 608, 607, 1086, 1085, 1879, 626, 3412, 2498, 1690, 2499, 2480, 1881, 2339, 2340, 2341, 3410, 3411, 3413, 2317, 2318, 2319, 617, 3150, 3149, 3155, 3201, 3200, 681, 837, 3761, 2682, 1420, 1427, 619, 2475, 1885, 1588, 3179, 1887, 1587, 3178, 176, 3599, 2322, 622, 2779, 2486, 1597, 1891, 2767, 1338, 428, 2878, 2476, 483, 3548, 2509, 3550, 1562, 727, 3486, 3230, 3658, 985, 664, 1956, 811, 2000, 955, 1501, 1426, 3501, 1258, 3199, 661, 988, 400, 366, 100, 350, 96, 931, 197, 1941, 805, 576, 2149, 2147, 419, 480, 559, 304, 223, 2162, 2142, 2153, 813, 935, 1795, 3253, 2188, 906, 3295, 2959, 2955, 1568, 496, 357, 226, 254, 312, 422, 566, 144, 2402, 3331, 1201, 1004, 1914, 3217, 3090, 3382, 1525, 2908, 1499, 697, 998, 3463, 3167, 2695, 2974, 3352, 3391, 399, 3357, 1833, 3388, 105, 2918, 2256, 1467, 2447, 1468, 1466, 1441, 1440, 2670, 2512, 2513, 2701, 3027, 1506, 1514, 2281, 2280, 1459, 2927, 1421, 521, 1517, 2303, 1529, 2915, 2958, 963, 2511, 326, 3436, 3442, 1561, 1924, 2391, 2494, 2399, 715, 3580, 1297, 3080, 1820, 2614, 274, 2481, 965, 3119, 585, 1895, 1896, 1900, 3639, 1052, 1792, 2030, 639, 1552, 1115, 1112, 1724, 1721, 1723, 1457, 1455, 1456, 1771, 1818, 2060, 967, 2145, 2824, 896, 895, 1012, 3225, 3224, 3630, 3629, 897, 898, 3258, 1971, 2028, 1970, 680, 1154, 1148, 692, 691, 699, 3257, 2090, 3177, 1628, 1652, 1850, 1014, 2923, 616, 1094, 2049, 3274, 2752, 1650, 1855, 2088, 930, 1599, 1660, 3768, 981, 993, 3292, 980, 992, 3291, 3226, 3631, 2029, 2708, 2117, 2115, 1711, 1942, 557, 3609, 852, 1889, 3048, 3049, 979, 978, 1593, 3182, 3187, 3504, 3508, 3512, 2228, 2227, 816, 3186, 1990, 177, 1806, 3784, 914, 3050, 2139, 2152, 738, 3260, 3488, 3248, 3492, 2717, 1686, 858, 859, 1793, 860, 2214, 3781, 2215, 2211, 2210, 3298, 1786, 1785, 2863, 1789, 1788, 3296, 1790, 3780, 3779, 3128, 3734, 1156, 3120, 2249, 2291, 1074, 371, 398, 1831, 310, 591, 2769, 474, 164, 84, 41, 385, 149, 2963, 792, 1939, 1948, 1731, 1596, 339, 1262, 2167, 2822, 2242, 380, 1520, 2859, 1425, 544, 497, 2374, 3688, 2384, 3690, 2855, 2185, 3718, 3059, 2749, 3061, 3235, 2058, 3733, 3739, 3679, 3692, 1476, 750, 1346, 2609, 3627, 3626, 903, 2385, 3500, 3520, 3545, 2987, 1431, 3395, 953, 3394, 1536, 1868, 145, 1540, 2258, 2255, 356, 2234, 1822, 3311, 3309, 1727, 1901, 717, 3479, 1683, 1684, 2697, 1797, 3771, 1828, 3215, 1077, 1838, 1695, 3506, 1985, 2741, 3711, 905, 3712, 3710, 2740, 2739, 2867, 2868, 3787, 3790, 2397, 949, 754, 749, 2107, 2043, 2565, 2736, 2392, 3738, 3313, 3241, 3262, 3259, 2721, 2033, 2032, 2035, 2715, 3315, 1842, 3816, 1070, 2232, 517, 2575, 3613, 2576, 2577, 583, 1826, 933, 2857, 1379, 3091, 2772, 1160, 1345, 3070, 941, 2835, 2853, 944, 2848, 3180, 721, 2400, 2183, 1829, 2240, 2316, 1067, 1812, 1810, 2275, 1018, 1699, 2926, 1763, 841, 3376, 1800, 1799, 3384, 3316, 2297, 2314, 1830, 2994, 1071, 3757, 3754, 1989, 3193, 1680, 359, 2504, 2403, 1106, 1863, 1663, 1665, 774, 1664, 712, 794, 2536, 2453, 3174, 3102, 472, 916, 2154, 2254, 2251, 1319, 1057, 2694, 2248, 2005, 3319, 939, 2245, 37, 3330, 2449, 2430, 2451, 3132, 2431, 345, 2382, 2373, 1298, 1309, 1402, 132, 43, 393, 424, 2945, 2780, 2998, 3601, 2999, 3625, 3637, 3041, 3118, 191, 1534, 1526, 3549, 2276, 3024, 1053, 1519, 2858, 974, 270, 590, 2170, 438, 140, 2907, 3731, 2206, 3770, 1589, 2130, 1110, 1225, 2119, 2488, 1399, 1755, 2144, 989, 1038, 1505, 3381, 2296, 1531, 2924, 3324, 1450, 3213, 3392, 2985, 3354, 2294, 3403, 3401, 1435, 1489, 2954, 1452, 3360, 3402, 3396, 1532, 3139, 849, 1055, 1056, 1322, 2189, 3797, 1360, 1361, 2380, 1625, 977, 1687, 2274, 1390, 510, 1174, 2110, 3534, 2597, 2606, 1400, 1404, 3579, 2548, 2714, 2193, 1350, 1349, 2137, 3737, 2016, 2015, 2825, 151, 2454, 3456, 1733, 1269, 3527, 2962, 2024, 2546, 2437, 2626, 3610, 2443, 2333, 1101, 2006, 1103, 1451, 2983, 928, 2309, 957, 1134, 2116, 2190, 2916, 3103, 1194, 2118, 2573, 3612, 3004, 2191, 1551, 2334, 3156, 3423, 2561, 1176, 353, 1276, 2849, 381, 56, 3283, 68, 441, 1718, 1132, 1315, 1102, 2261, 101, 2398, 1448, 1207, 686, 2026, 1109, 1098, 3323, 1127, 2446, 2067, 98, 2545, 725, 2946, 83, 338, 666, 509, 170, 3161, 588, 209, 2753, 1777, 3374, 3375, 3273, 526, 667, 2562, 21, 2756, 3350, 2551, 344, 354, 1509, 1496, 2894, 2912, 966, 1320, 2541, 1504, 1359, 885, 2906, 3461, 3460, 3493, 696, 695, 1640, 739, 2491, 2046, 131, 2640, 2002, 2896, 960, 414, 3088, 255, 230, 558, 3317, 93, 975, 2770, 516, 1334, 2113, 1372, 891, 3707, 3047, 890, 1374, 2207, 2745, 3744, 2854, 2379, 1095, 2505, 89, 1128, 142, 90, 2549, 305, 1335, 2550, 2698, 1290, 1533, 1824, 1832, 1813, 1475, 987, 1997, 1027, 1026, 1025, 1666, 3232, 899, 904, 920, 3263, 3621, 3192, 1794, 1801, 2224, 2720, 3766, 3804, 1073, 1079, 1075, 3129, 2175, 1867, 155, 3264, 25, 1825, 554, 114, 560, 206, 455, 1761, 3487, 1024, 1674, 1662, 1661, 1646, 1648, 1647, 1045, 926, 1870, 976, 1572, 1865, 1869, 1573, 2725, 1717, 314, 185, 32, 934, 1373, 892, 1535, 3484, 2679, 3377, 1333, 2881, 3728, 843, 3112, 3113, 3110, 1331, 2879, 1343, 3743, 2041, 3708, 3729, 3111, 3791, 683, 3051, 3474, 798, 268, 2902, 1791, 2495, 1988, 3431, 1560, 3597, 3592, 2705, 475, 3566, 2393, 444, 1188, 3559, 2008, 3022, 872, 2645, 638, 3355, 1042, 2160, 2298, 807, 2299, 2989, 756, 3189, 744, 2901, 2649, 610, 1903, 3543, 611, 2353, 1092, 2420, 1621, 3567, 3588, 1765, 2526, 809, 665, 815, 764, 3516, 1444, 1502, 244, 1749, 2300, 1511, 2066, 3741, 470, 800, 2222, 3715, 3716, 3574, 481, 2627, 139, 235, 473, 150, 368, 190, 262, 525, 2091, 161, 104, 3454, 442, 416, 2644, 3017, 2637, 2631, 283, 1703, 1698, 1996, 1987, 1237, 870, 1710, 2003, 2871, 2874, 3106, 3108, 410, 1199, 3481, 720, 3372, 3373, 1058, 1059, 2642, 3677, 3683, 825, 1254, 1270, 786, 787, 785, 3535, 1255, 1899, 1251, 1257, 1470, 1491, 1171, 3339, 3332, 1164, 3325, 1485, 2283, 2282, 3326, 861, 862, 814, 122, 458, 3255, 1130, 1471, 3137, 1249, 2312, 1386, 2310, 3127, 2690, 3358, 1488, 3340, 1432, 1423, 826, 2662, 757, 3390, 1428, 3774, 1503, 3400, 1487, 3097, 1481, 3023, 1177, 1738, 2500, 478, 1347, 847, 10, 3740, 846, 1784, 489, 3195, 1624, 3333, 3730, 2861, 1364, 1527, 2984, 2771, 1500, 1454, 1453, 3363, 1512, 1515, 2173, 3099, 2862, 2199, 1518, 3109, 459, 449, 1909, 3552, 1162, 1907, 3547, 1161, 1753, 2899, 2351, 1906, 3553, 1158, 685, 2062, 3071, 1905, 3546, 2065, 3735, 1342, 3655, 2489, 2777, 1405, 2688, 883, 2020, 3638, 3482, 1356, 1203, 1250, 1357, 1197, 3595, 2986, 1139, 2371, 2533, 1035, 2530, 1945, 3356, 1944, 3096, 1908, 1344, 2883, 1852, 1972, 2563, 1712, 763, 1979, 752, 3229, 3228, 1140, 2558, 76, 684, 3736, 3666, 1590, 1595, 2473, 1586, 1417, 1114, 634, 2479, 117, 315, 341, 2843, 3087, 267, 348, 1409, 922, 321, 1084, 2225, 2194, 971, 570, 182, 584, 1341, 2768, 3544, 2911, 2909, 2346, 2350, 609, 1902, 3542, 2348, 2786, 1403, 1137, 2988, 2808, 2330, 234, 238, 2086, 2085, 147, 402, 1305, 2830, 2798, 2416, 2415, 396, 108, 392, 2799, 2817, 66, 2806, 157, 390, 839, 842, 3526, 469, 2239, 1370, 1845, 3019, 1007, 3347, 3345, 1008, 1009, 1049, 1048, 869, 1355, 3361, 3398, 2308, 2313, 1080, 1082, 863, 3190, 2712, 784, 2735, 1634, 2734, 778, 1636, 924, 1836, 1633, 2706, 1637, 1993, 2017, 2413, 1642, 1143, 1260, 3249, 878, 877, 1639, 762, 1498, 3237, 3473, 3272, 746, 1630, 1631, 3252, 2045, 2722, 2723, 78, 555, 1643, 1565, 187, 503, 452, 35, 3219, 1644, 461, 259, 1397, 2081, 2925, 1383, 2435, 942, 3445, 1766, 1313, 1178, 2158, 996, 3478, 1422, 3353, 3122, 1436, 3399, 1424, 432, 3335, 3334, 3166, 3175, 2184, 1937, 1044, 2172, 1040, 2031, 2192, 1796, 1054, 1798, 1069, 3300, 2865, 948, 3786, 308, 2304, 2195, 3785, 3297, 564, 467, 502, 3589, 3220, 1969, 3660, 918, 1760, 1742, 2246, 2893, 676, 674, 1943, 1953, 1951, 659, 1960, 1611, 1967, 1952, 334, 265, 355, 1946, 1968, 1629, 14, 121, 1959, 677, 456, 678, 395, 34, 212, 44, 63, 493, 3054, 1999, 2042, 3028, 3029, 2660, 1980, 1706, 3669, 3397, 2619, 2724, 2587, 1256, 2666, 2665, 759, 2588, 2667, 2586, 1240, 2241, 257, 679, 3783, 2884, 946, 969, 2764, 2775, 2766, 2765, 2840, 261, 141, 74, 451, 22, 16, 3607, 3604, 2713, 1632, 1751, 1866, 3608, 2658, 2656, 3618, 775, 1215, 2603, 1688, 2372, 1213, 546, 127, 159, 423, 2559, 597, 2683, 293, 282, 129, 599, 281, 208, 168, 65, 3476, 2198, 1773, 1371, 894, 3101, 3020, 3266, 3265, 2729, 2731, 2732, 2733, 723, 3276, 3726, 833, 1047, 1779, 2204, 1667, 2995, 2730, 1205, 3483, 1567, 3773, 2801, 3094, 919, 2267, 3285, 1068, 3756, 1821, 940, 3775, 1477, 1479, 2287, 3364, 1774, 2200, 2864, 3299, 3789, 1146, 2250, 1261, 986, 1758, 2965, 2960, 2964, 2148, 1285, 3162, 2810, 2165, 1304, 658, 2527, 819, 3727, 1330, 690, 2352, 1226, 1230, 1600, 1759, 1894, 640, 937, 1241, 2949, 2004, 2266, 2623, 71, 1410, 1149, 2876, 2917, 1414, 947, 835, 834, 375, 1192, 1442, 2875, 484, 1096, 487, 1265, 615, 1566, 1564, 1929, 2396, 309, 266, 2602, 2669, 2668, 2930, 2664, 2284, 1234, 1486, 1482, 1236, 2624, 2629, 2762, 3056, 1358, 1307, 2860, 1516, 889, 1685, 1668, 418, 2583, 1569, 1546, 1775, 3814, 2202, 3301, 3788, 1776, 263, 61, 327, 322, 331, 158, 81, 3336, 2053, 991, 3275, 2755, 1651, 1037, 984, 716, 1673, 1675, 2106, 2108, 2109, 3776, 3093, 2555, 3665, 2089, 3244, 3173, 1977, 3231, 1689, 3659, 3663, 3662, 1010, 650, 652, 3661, 445, 1893, 672, 669, 165, 541, 446, 2150, 51, 249, 320, 454, 2838, 233, 2851, 195, 492, 2163, 824, 840, 810, 1310, 285, 1469, 1416, 2596, 2589, 384, 2301, 2302, 1539, 408, 2957, 1244, 2590, 2671, 1897, 2593, 2594, 2595, 2673, 2675, 2672, 2674, 1144, 2703, 893, 3136, 1530, 3134, 434, 2501, 726, 1202, 2942, 3470, 708, 1200, 3812, 1182, 1848, 362, 3140, 3509, 3418, 3530, 3531, 2761, 2055, 2264, 781, 782, 1111, 1113, 3422, 1116, 2728, 1180, 710, 606, 403, 18, 2872, 1437, 2525, 317, 2647, 3685, 766, 1348, 1787, 2213, 1363, 850, 3606, 3000, 2564, 3605, 851, 1301, 533, 2448, 3521, 2492, 2259, 2951, 1991, 2272, 1166, 1657, 2928, 3451, 3138, 2993, 2742, 3058, 3714, 907, 1321, 2503, 1136, 2425, 3554, 124, 598, 347, 3537, 1163, 1100, 2773, 2866, 3107, 3105, 950, 1412, 1411, 1413, 2635, 2554, 1316, 1317, 2852, 2633, 2069, 2080, 2599, 2711, 2598, 2961, 2600, 2601, 3416, 3415, 3650, 3649, 630, 3644, 3643, 2785, 2582, 2580, 2727, 2257, 1847, 2243, 2428, 2700, 2252, 2009, 3645, 1607, 654, 1619, 748, 2123, 252, 2975, 2982, 2543, 53, 2944, 237, 19, 298, 3587, 271, 54, 292, 323, 2375, 73, 391, 330, 163, 88, 1617, 2903, 1627, 2537, 547, 160, 2744, 453, 3536, 318, 58, 335, 2076, 407, 2837, 376, 358, 2423, 72, 1362, 2354, 1105, 1108, 3648, 3633, 880, 2659, 2652, 1655, 701, 3533, 2696, 1229, 437, 64, 289, 119, 109, 379, 513, 1808, 3055, 2320, 3126, 2057, 3742, 2383, 2747, 1263, 1190, 2168, 2681, 3652, 879, 2655, 2657, 3628, 3632, 3651, 2654, 2653, 466, 3434, 476, 1287, 571, 412, 324, 397, 280, 372, 2941, 1927, 1204, 722, 3725, 3063, 3065, 2050, 1329, 830, 832, 970, 3085, 1209, 3682, 3673, 2634, 3674, 3678, 2625, 3077, 3092, 2156, 1443, 2186, 2921, 2743, 3057, 3713, 1323, 3222, 3223, 2040, 1264, 769, 3341, 1719, 3453, 3676, 3806, 3813, 2093, 3615, 2578, 3684, 765, 112, 770, 1165, 3227, 3642, 2212, 3593, 2197, 3792, 3115, 2882, 2209, 1521, 2070, 534, 2444, 1179, 3541, 3561, 2869, 2784, 1995, 962, 1816, 3124, 2622, 1181, 2608]\n",
            "2803\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 381,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrgS06MOCvEr"
      },
      "source": [
        "#Because I don't want to mess up my inputs and outputs, I test their lengths before and after the outlier filtering.\n",
        "assert(len(input) == len(output))\n",
        "\n",
        "newinput=[]\n",
        "newoutput=[]\n",
        "\n",
        "for i in range(len(output)):\n",
        "    if(output[i] not in outliers):\n",
        "        newinput.append(input[i])\n",
        "        newoutput.append(output[i])\n",
        "\n",
        "input = newinput\n",
        "output = newoutput\n",
        "\n",
        "assert(len(input) == len(output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqrdwosCwPn"
      },
      "source": [
        "#However, this outlier filtering made things complicated. Now I have to make a new mapper, so that i won't end up with output classes containing 0 elements.\n",
        "\n",
        "mapper_list = [] #Idx of the mapper list is the new value, the element is the old value.\n",
        "new_output_elements = set(output)\n",
        "\n",
        "for i in new_output_elements:\n",
        "    mapper_list.append(i)\n",
        "\n",
        "newoutput = []\n",
        "\n",
        "for i in output:\n",
        "    newoutput.append(mapper_list.index(i))\n",
        "\n",
        "output = newoutput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqaL4N9eCxCZ"
      },
      "source": [
        "#Reshaping the input data to be compatible with LSTMs and normalizing it in the hope of better learning.\n",
        "\n",
        "input = np.reshape(np.asarray(input), (len(input), SLICE_LEN, 1))\n",
        "#output = to_categorical(output)\n",
        "\n",
        "#input=np.asarray(input) / float(len(mapper))\n",
        "output=np.asarray(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv2INnZOCx3O",
        "outputId": "f9d12d2c-4a10-4b89-a06b-f1115223f721"
      },
      "source": [
        "SEED = 54\n",
        "#np.random.seed(SEED)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(input, output, test_size=0.01, random_state=SEED)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=SEED)\n",
        "\n",
        "startidx = np.random.randint(0, len(X_test)-1)\n",
        "starting_slice = X_test[startidx]\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "print(startidx)\n",
        "print(starting_slice)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(176576, 20, 1) (44144, 20, 1) (2230, 20, 1) (176576,) (44144,) (2230,)\n",
            "1887\n",
            "[[1700]\n",
            " [1936]\n",
            " [1934]\n",
            " [1030]\n",
            " [1030]\n",
            " [ 789]\n",
            " [3209]\n",
            " [1602]\n",
            " [1936]\n",
            " [1934]\n",
            " [1030]\n",
            " [1030]\n",
            " [ 789]\n",
            " [3209]\n",
            " [1602]\n",
            " [1936]\n",
            " [1934]\n",
            " [1030]\n",
            " [1030]\n",
            " [ 789]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mr4do7ObAOn"
      },
      "source": [
        "# MODEL TRAINING SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txOwScdfGCoS"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# DATA GENERATOR\n",
        "NUM_CLASSES = to_categorical(Y_train).shape[1]\n",
        "SLICE_SIZE = SLICE_LEN\n",
        "\n",
        "class MyDatagen(Sequence):\n",
        "  def __init__(self, list_IDs, batch_size=16, dim=(SLICE_SIZE), shuffle=True, validation=False):\n",
        "    'Initialization'\n",
        "    self.dim = dim\n",
        "    self.batch_size = batch_size\n",
        "    self.list_IDs = list_IDs\n",
        "    self.shuffle = shuffle\n",
        "    self.validation=validation\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Generate indexes of the batch\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "    # Generate data\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "      #Updates indexes after each epoch\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    #Generates data containing batch_size samples\n",
        "    if self.validation:\n",
        "      X = np.empty((self.batch_size, self.dim, 1))\n",
        "      y = np.empty((self.batch_size, NUM_CLASSES))\n",
        "\n",
        "      # Generate data\n",
        "      for i, ID in enumerate(list_IDs_temp):\n",
        "        X[i] = X_val[ID]\n",
        "\n",
        "        y[i] = to_categorical(Y_val[ID], num_classes=NUM_CLASSES)\n",
        "\n",
        "      return X, y\n",
        "    else:\n",
        "      X = np.empty((self.batch_size, self.dim, 1))\n",
        "      y = np.empty((self.batch_size, NUM_CLASSES))\n",
        "\n",
        "      # Generate data\n",
        "      for i, ID in enumerate(list_IDs_temp):\n",
        "        X[i] = X_train[ID]\n",
        "\n",
        "        y[i] = to_categorical(Y_train[ID], num_classes=NUM_CLASSES)\n",
        "\n",
        "      return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8_sRgmI-mT"
      },
      "source": [
        "MODEL_NAME = \"Attention_guitar_2\"\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/MLFolder/Onlab/modelsaves/\"\n",
        "\n",
        "TBPATH = \"/content/tblogs/\"+MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Jc9A39bLzY"
      },
      "source": [
        "#Before creating the neural network, I define some important callbacks\n",
        "\n",
        "tb = TensorBoard(log_dir = TBPATH, write_images=True, histogram_freq=1)\n",
        "\n",
        "plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00005, verbose=1)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience = 5, restore_best_weights = True, verbose=1)\n",
        "\n",
        "callbacks = [plateau, es, tb]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LImJHAXeRhrO"
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "import math as m\n",
        "\n",
        "class DynamicPositionEmbedding(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        embedding_dim=256\n",
        "        max_seq=2048\n",
        "        embed_sinusoid_list = np.array([[\n",
        "            [\n",
        "                m.sin(\n",
        "                    pos * m.exp(-m.log(10000) * i/embedding_dim) *\n",
        "                    m.exp(m.log(10000)/embedding_dim * (i % 2)) + 0.5 * m.pi * (i % 2)\n",
        "                )\n",
        "                for i in range(embedding_dim)\n",
        "            ]\n",
        "            for pos in range(max_seq)\n",
        "        ]])\n",
        "        self.positional_embedding = tf.constant(embed_sinusoid_list, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.add(inputs, self.positional_embedding[:,:inputs.shape[1],:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbZ73wx8bN2u"
      },
      "source": [
        "#I create the neural network model here.\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Attention\n",
        "from tensorflow.keras.layers import Embedding, Reshape, Dropout\n",
        "from tensorflow.keras.layers import Input, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(SLICE_LEN,1))\n",
        "x = Embedding(len(mapper), 256, input_length=SLICE_LEN)(input_layer)\n",
        "x = Reshape((SLICE_LEN,256))(x)\n",
        "x = DynamicPositionEmbedding()(x)\n",
        "x = MultiHeadAttention(num_heads=16, key_dim=10, dropout=0.1)(x,x)\n",
        "x = Flatten()(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(input_layer, output)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "training_gen=MyDatagen(range(X_train.shape[0]), dim = SLICE_LEN, batch_size=16)\n",
        "val_gen=MyDatagen(range(X_val.shape[0]), dim = SLICE_LEN, batch_size=16, validation=True)\n",
        "\n",
        "model.fit(training_gen, epochs=10000, validation_data=val_gen, callbacks=callbacks)\n",
        "\n",
        "model.evaluate(X_test, to_categorical(Y_test, num_classes=NUM_CLASSES))\n",
        "\n",
        "model.save(MODEL_SAVE_PATH + MODEL_NAME + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEz6abeWwstN",
        "outputId": "0df1fd71-3fff-495d-dc74-c4f1abb4d93d"
      },
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention, Attention\n",
        "from tensorflow.keras.layers import Embedding, Reshape, LSTM\n",
        "from tensorflow.keras.layers import Input, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#LSTM + Attention\n",
        "\n",
        "input_layer = Input(shape=(SLICE_LEN,1))\n",
        "x = LSTM(512, return_sequences=True)(input_layer)\n",
        "x = LSTM(256, return_sequences=True)(x)\n",
        "attn_out = MultiHeadAttention(num_heads=16, key_dim=10, dropout=0.1)(x,x)\n",
        "x = Flatten()(attn_out)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model2 = Model(input_layer, output)\n",
        "\n",
        "model2.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "training_gen=MyDatagen(range(X_train.shape[0]), dim = 20, batch_size=16)\n",
        "val_gen=MyDatagen(range(X_val.shape[0]), dim = 20, batch_size=16, validation=True)\n",
        "\n",
        "model2.fit(X_train/len(mapper), to_categorical(Y_train), epochs=10000, validation_data=(X_val/len(mapper), to_categorical(Y_val)), callbacks=callbacks)\n",
        "\n",
        "model2.evaluate(X_test/len(mapper), to_categorical(Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5518/5518 [==============================] - 60s 10ms/step - loss: 4.4852 - accuracy: 0.1233 - val_loss: 3.7217 - val_accuracy: 0.2400\n",
            "Epoch 2/10000\n",
            "5518/5518 [==============================] - 56s 10ms/step - loss: 3.0236 - accuracy: 0.3710 - val_loss: 2.5033 - val_accuracy: 0.4701\n",
            "Epoch 3/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 2.0721 - accuracy: 0.5476 - val_loss: 2.0015 - val_accuracy: 0.5780\n",
            "Epoch 4/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 1.5932 - accuracy: 0.6360 - val_loss: 1.7399 - val_accuracy: 0.6411\n",
            "Epoch 5/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 1.3030 - accuracy: 0.6933 - val_loss: 1.6578 - val_accuracy: 0.6687\n",
            "Epoch 6/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 1.1076 - accuracy: 0.7338 - val_loss: 1.5980 - val_accuracy: 0.6870\n",
            "Epoch 7/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.9651 - accuracy: 0.7647 - val_loss: 1.6303 - val_accuracy: 0.7099\n",
            "Epoch 8/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.8609 - accuracy: 0.7872 - val_loss: 1.5525 - val_accuracy: 0.7191\n",
            "Epoch 9/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.7769 - accuracy: 0.8074 - val_loss: 1.5353 - val_accuracy: 0.7316\n",
            "Epoch 10/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.7153 - accuracy: 0.8230 - val_loss: 1.5565 - val_accuracy: 0.7395\n",
            "Epoch 11/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.6625 - accuracy: 0.8349 - val_loss: 1.5589 - val_accuracy: 0.7413\n",
            "Epoch 12/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.6168 - accuracy: 0.8454 - val_loss: 1.6335 - val_accuracy: 0.7391\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 13/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.3105 - accuracy: 0.9179 - val_loss: 1.4599 - val_accuracy: 0.7896\n",
            "Epoch 14/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.2328 - accuracy: 0.9351 - val_loss: 1.4920 - val_accuracy: 0.7882\n",
            "Epoch 15/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.2104 - accuracy: 0.9412 - val_loss: 1.4911 - val_accuracy: 0.7926\n",
            "Epoch 16/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1980 - accuracy: 0.9440 - val_loss: 1.5170 - val_accuracy: 0.7949\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "Epoch 17/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1462 - accuracy: 0.9576 - val_loss: 1.5788 - val_accuracy: 0.8000\n",
            "Epoch 18/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1320 - accuracy: 0.9596 - val_loss: 1.5954 - val_accuracy: 0.8000\n",
            "Epoch 19/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1264 - accuracy: 0.9603 - val_loss: 1.6131 - val_accuracy: 0.8001\n",
            "Epoch 20/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1236 - accuracy: 0.9612 - val_loss: 1.6306 - val_accuracy: 0.8021\n",
            "Epoch 21/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1217 - accuracy: 0.9620 - val_loss: 1.6345 - val_accuracy: 0.8016\n",
            "Epoch 22/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1206 - accuracy: 0.9622 - val_loss: 1.6405 - val_accuracy: 0.8029\n",
            "Epoch 23/10000\n",
            "5518/5518 [==============================] - 55s 10ms/step - loss: 0.1198 - accuracy: 0.9625 - val_loss: 1.6636 - val_accuracy: 0.7997\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5111 - accuracy: 0.7789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5110688209533691, 0.778923749923706]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}